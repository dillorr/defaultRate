{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyforest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import dataset without foreign schools\n",
    "df = pd.read_csv(r'/Users/dillorr/defaultRate/dillon/defaultRate/data/modeling/combined.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the opeid column as the feature to be predicted (y)\n",
    "y = df['proprietary']\n",
    "\n",
    "# Remove the opeid column to create the training data\n",
    "X = df.drop('proprietary', axis=1)\n",
    "\n",
    "# Perform a 70% train and 30% test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "train = pd.concat([y_train, X_train], axis = 1)\n",
    "test = pd.concat([y_test, X_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training and test\n",
    "train.to_csv('/Users/dillorr/defaultRate/dillon/defaultRate/data/modeling/train.csv', index=False)\n",
    "test.to_csv('/Users/dillorr/defaultRate/dillon/defaultRate/data/modeling/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proprietary', 'opeid', 'agemedian', 'cdr2014_log', 'cdr2015_log',\n",
       "       'cdr2016_log', 'cohort2014_log', 'cohort2015_log', 'cohort2016_log',\n",
       "       'density_log', 'educationcollegeorabove', 'familysize_log',\n",
       "       'female_sqrt', 'homeownership', 'homevalue_log',\n",
       "       'incomehouseholdmedian_log', 'incomehouseholdsixfigure_log',\n",
       "       'laborforceparticipation_sqrt', 'male_reciprocal', 'married',\n",
       "       'population_log', 'proglength', 'raceasian_log', 'raceblack_log',\n",
       "       'racemultiple_log', 'racenative_reciprocal', 'raceother_log',\n",
       "       'racepacific', 'racewhite', 'rentmedian_log', 'unemploymentrate_log',\n",
       "       'associates', 'bachelors', 'firstprofessional', 'gradprofessional',\n",
       "       'mastersordoctors', 'nondegree', 'nondegree1year', 'nondegree2years',\n",
       "       'nondegree3years', 'private', 'public', 'hbcuCollege',\n",
       "       'hispanicCollege', 'nativeAmericanCollege', 'notReportedCollege'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            proprietary   No. Observations:                 2693\n",
      "Model:                            GLM   Df Residuals:                     2681\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1529.7\n",
      "Date:                Mon, 06 Apr 2020   Deviance:                       3059.3\n",
      "Time:                        20:07:05   Pearson chi2:                 2.72e+03\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                       -6.4133      0.821     -7.814      0.000      -8.022      -4.805\n",
      "cdr2016_log                      3.1799      0.282     11.277      0.000       2.627       3.733\n",
      "agemedian                        3.4905      0.652      5.357      0.000       2.214       4.768\n",
      "density_log                      1.1934      0.689      1.732      0.083      -0.157       2.544\n",
      "familysize_log                   3.5804      0.647      5.533      0.000       2.312       4.849\n",
      "homeownership                    1.9658      0.632      3.109      0.002       0.726       3.205\n",
      "incomehouseholdmedian_log       -3.5257      0.899     -3.921      0.000      -5.288      -1.763\n",
      "laborforceparticipation_sqrt    -4.1910      0.794     -5.280      0.000      -5.747      -2.635\n",
      "population_log                   1.5681      0.340      4.612      0.000       0.902       2.234\n",
      "raceasian_log                    1.8493      0.422      4.381      0.000       1.022       2.677\n",
      "racenative_reciprocal            0.4017      0.249      1.611      0.107      -0.087       0.891\n",
      "racewhite                        1.6087      0.359      4.479      0.000       0.905       2.313\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, glm\n",
    "\n",
    "formula = 'proprietary ~ cdr2016_log + agemedian + density_log + familysize_log + homeownership + incomehouseholdmedian_log + laborforceparticipation_sqrt + population_log + raceasian_log + racenative_reciprocal + racewhite'\n",
    "\n",
    "\n",
    "# binomial\n",
    "family_GLM = sm.families.Binomial()\n",
    "\n",
    "\n",
    "# Fit a linear model\n",
    "model_lm = glm(formula = formula,\n",
    "               data = train, family = family_GLM).fit()\n",
    "\n",
    "# View model summary\n",
    "print(model_lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          548   74  622\n",
      "1          184   92  276\n",
      "All        732  166  898\n",
      "\n",
      "\n",
      "Evaluation Metrics\n",
      "Accuracy:  71.3 %\n",
      "Precision:  74.9 %\n",
      "Recall:  88.1 %\n",
      "Sensitivity:  88.1 %\n",
      "Specificity:  33.3 %\n",
      "Kappa:  24.1 %\n"
     ]
    }
   ],
   "source": [
    "pred_lm = model_lm.predict(X_test)\n",
    "\n",
    "# Define the cutoff\n",
    "cutoff = 0.5\n",
    "\n",
    "# Compute class predictions: y_prediction\n",
    "y_prediction = np.where(pred_lm > cutoff, 1, 0)\n",
    "\n",
    "# Compute the confusion matrix using crosstab function\n",
    "conf_mat = pd.crosstab(y_test, y_prediction,\n",
    "                       rownames=['Actual'], \n",
    "                       colnames=['Predicted'], \n",
    "                       margins = True)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix')\n",
    "print(conf_mat)\n",
    "\n",
    "tp = conf_mat.iloc[0,0]\n",
    "fp = conf_mat.iloc[1,0]\n",
    "tn = conf_mat.iloc[1,1]\n",
    "fn = conf_mat.iloc[0,1]\n",
    "\n",
    "\n",
    "accuracy = (tn + tp)/(tn+ tp + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "sensitivity = tp/(tp + fn)\n",
    "specificity = tn/(tn + fp)\n",
    "\n",
    "print('\\n')\n",
    "print('Evaluation Metrics')\n",
    "print('Accuracy: ', ((accuracy)*100).round(1), '%')\n",
    "print('Precision: ', ((precision)*100).round(1), '%')\n",
    "print('Recall: ', ((recall)*100).round(1), '%')\n",
    "print('Sensitivity: ', ((sensitivity)*100).round(1), '%')\n",
    "print('Specificity: ', ((specificity)*100).round(1), '%')\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, y_prediction)\n",
    "\n",
    "print('Kappa: ', ((kappa)*100).round(1), '%',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
